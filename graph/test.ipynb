{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-17T16:10:18.948078800Z",
     "start_time": "2024-06-17T16:10:17.667405Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from app.tools.models.select_llms import get_llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "llm_config = {\n",
    "    \"provider\":\"openai\",\n",
    "    \"model\":\"gpt-4o-ca\"\n",
    "}\n",
    "llm = get_llms(llm_config)\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T16:10:28.322071700Z",
     "start_time": "2024-06-17T16:10:28.289992600Z"
    }
   },
   "id": "f12d62fd9bfb5a06"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 截至目前，我对“langgraph”这个术语并没有具体的信息。可能是因为它是一个非常新颖的概念、特定领域的术语，或者是一个尚未广泛传播的术语。\n",
      "\n",
      "如果你能提供更多的上下文或详细信息，我可能可以更好地帮助你理解这个概念。比如，它是涉及到计算机科学、语言学、数据可视化，还是其他领域？任何额外的信息都会有所帮助。\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGoodbye!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m graph\u001B[38;5;241m.\u001B[39mstream({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, user_input)}):\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m value \u001B[38;5;129;01min\u001B[39;00m event\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m     12\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAssistant:\u001B[39m\u001B[38;5;124m\"\u001B[39m, value[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mcontent)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\littleagent-Hn7clQwO-py3.10\\lib\\site-packages\\langgraph\\pregel\\__init__.py:949\u001B[0m, in \u001B[0;36mPregel.stream\u001B[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001B[0m\n\u001B[0;32m    943\u001B[0m end_time \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    944\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_timeout \u001B[38;5;241m+\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m    945\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_timeout\n\u001B[0;32m    946\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    947\u001B[0m )\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m futures:\n\u001B[1;32m--> 949\u001B[0m     done, inflight \u001B[38;5;241m=\u001B[39m \u001B[43mconcurrent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfutures\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    950\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    951\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_when\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcurrent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfutures\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFIRST_COMPLETED\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    952\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_time\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmonotonic\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    953\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mend_time\u001B[49m\n\u001B[0;32m    954\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    955\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    956\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m fut \u001B[38;5;129;01min\u001B[39;00m done:\n\u001B[0;32m    957\u001B[0m         task \u001B[38;5;241m=\u001B[39m futures\u001B[38;5;241m.\u001B[39mpop(fut)\n",
      "File \u001B[1;32mD:\\Python310\\lib\\concurrent\\futures\\_base.py:307\u001B[0m, in \u001B[0;36mwait\u001B[1;34m(fs, timeout, return_when)\u001B[0m\n\u001B[0;32m    303\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001B[0;32m    305\u001B[0m     waiter \u001B[38;5;241m=\u001B[39m _create_and_install_waiters(fs, return_when)\n\u001B[1;32m--> 307\u001B[0m \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m fs:\n\u001B[0;32m    309\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m f\u001B[38;5;241m.\u001B[39m_condition:\n",
      "File \u001B[1;32mD:\\Python310\\lib\\threading.py:607\u001B[0m, in \u001B[0;36mEvent.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    605\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[0;32m    606\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[1;32m--> 607\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[1;32mD:\\Python310\\lib\\threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "graph = graph_builder.compile()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T16:11:49.822664600Z",
     "start_time": "2024-06-17T16:10:40.259081200Z"
    }
   },
   "id": "748ade2ef3baf158"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',\n  'content': 'Nodes: Nodes are the building blocks of your LangGraph. Each node represents a function or a computation step. You define nodes to perform specific tasks, such as processing input, making ...'},\n {'url': 'https://langchain-ai.github.io/langgraph/',\n  'content': 'LangGraph is framework agnostic (each node is a regular python function). It extends the core Runnable API (shared interface for streaming, async, and batch calls) to make it easy to: Seamless state management across multiple turns of conversation or tool usage. The ability to flexibly route between nodes based on dynamic criteria.'}]"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = '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'\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T15:28:46.794286Z",
     "start_time": "2024-06-21T15:28:40.559938600Z"
    }
   },
   "id": "4e33b25b362e4e07"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from app.tools.models.select_llms import get_llms\n",
    "llm_config = {\n",
    "    \"provider\":\"openai\",\n",
    "    \"model\":\"gpt-4o-ca\"\n",
    "}\n",
    "llm = get_llms(llm_config)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T15:30:52.601032200Z",
     "start_time": "2024-06-21T15:30:52.555380700Z"
    }
   },
   "id": "fce9a2dc747fe2fa"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T15:31:22.518881800Z",
     "start_time": "2024-06-21T15:31:22.453063300Z"
    }
   },
   "id": "8f79f2a14189752f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T15:33:05.264746400Z",
     "start_time": "2024-06-21T15:33:05.250001Z"
    }
   },
   "id": "bf73646e6c2a0396"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def route_tools(\n",
    "    state: State,\n",
    ") -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"__end__\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T15:33:32.241339700Z",
     "start_time": "2024-06-21T15:33:32.220017500Z"
    }
   },
   "id": "344d61e6e37cdf0d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T15:33:46.882751600Z",
     "start_time": "2024-06-21T15:33:44.923354100Z"
    }
   },
   "id": "765160e3e489fd71"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "Assistant: [{\"url\": \"https://langchain-ai.github.io/langgraph/tutorials/\", \"content\": \"Basic Reflection: Prompting the agent to reflect on and revise its outputs. Reflexion: Critiquing missing and superfluous details to guide next steps. Language Agent Tree Search: Using reflection and rewards to drive a tree search over agents. Self-Discovering Agent: Analyzing an agent that learns about its own capabilities.\"}, {\"url\": \"https://blog.csdn.net/weixin_41496173/article/details/139023846\", \"content\": \"1.\\u4ec0\\u4e48\\u662fLangGraph\\uff1f. \\u9996\\u5148\\u4e00\\u53e5\\u8bdd\\u6982\\u62ecLangGraph\\uff1a\\u53ef\\u4ee5\\u5b9e\\u73b0\\u57fa\\u4e8eLLM\\u667a\\u80fd\\u52a9\\u624b\\uff08LLM Agent\\uff09\\u7684\\u795e\\u4ed9\\u6846\\u67b6!. LangGraph\\u662f\\u5728LLM\\u548cLangChain\\u7684\\u57fa\\u7840\\u4e4b\\u4e0a\\u53d1\\u5c55\\u800c\\u6765\\uff0cLangGraph\\u5e93\\u672c\\u8eab\\u57fa\\u4e8eLangChain\\u5e93\\uff0c\\u5982\\u4e0b\\u56fe\\u6240\\u793a\\u3002. \\u5982\\u679c\\u4ec5\\u4f7f\\u7528LLM\\uff0c\\u4e00\\u822c\\u7528\\u4e8e\\u5b9e\\u73b0 \\u65e0\\u5916\\u90e8\\u5de5\\u5177\\u3001\\u65e0\\u53cd\\u9988\\u7684 \\u95ee\\u7b54\\u4efb\\u52a1\\uff1b\\u57fa\\u4e8eLangChain ...\"}]\n",
      "Assistant: 要学习LangGraph，可以参考以下资源：\n",
      "\n",
      "1. **LangGraph官方教程**:\n",
      "   - 访问 [LangGraph教程](https://langchain-ai.github.io/langgraph/tutorials/) 页面，提供了详细的教程和示例，帮助你理解和使用LangGraph。\n",
      "\n",
      "2. **CSDN博客文章**:\n",
      "   - 阅读CSDN上的文章 [什么是LangGraph](https://blog.csdn.net/weixin_41496173/article/details/139023846)，这篇文章介绍了LangGraph的基本概念及其与LLM和LangChain的关系。\n",
      "\n",
      "通过这些资源，你可以系统地学习LangGraph的使用方法和应用场景。\n",
      "Assistant: \n",
      "Assistant: [{\"url\": \"https://spectrum.ieee.org/the-top-programming-languages-2023\", \"content\": \"Topics\\nSections\\nMore\\nFor IEEE Members\\nFor IEEE Members\\nIEEE Spectrum\\nFollow IEEE Spectrum\\nSupport IEEE Spectrum\\nEnjoy more free content and benefits by creating an account\\nSaving articles to read later requires an IEEE Spectrum account\\nThe Institute content is only available for members\\nDownloading full PDF issues is exclusive for IEEE Members\\nAccess to Spectrum's Digital Edition is exclusive for IEEE Members\\n Another would be Smalltalk... far less than RPG but more than many on your list\\nVolunteer Training Program Sees Record Growth As it Marks 10 Years\\nGenerating Power on Earth From the Coldness of Deep Space\\nSatellite-Sharing Enables Low-Cost Earth Observation\\nRelated Stories\\nPython Profiler Links to AI to Improve Code\\nHow Python Swallowed the World\\nTop Programming Languages Methodology Following topics is a feature exclusive for IEEE Members\\nAdding your response to an article requires an IEEE Spectrum account\\nCreate an account to access more content and features on IEEE Spectrum, including the ability to save articles to read later, download Spectrum Collections, and participate in conversations with readers and editors. The Top Programming Languages 2023\\nPython and SQL are on top, but old languages shouldn\\u2019t be forgotten\\nPython and SQL are on top, but old languages shouldn\\u2019t be forgotten\\nWelcome to IEEE Spectrum\\u2019s 10th annual rankings of the Top Programming Languages. While the way we put the TPL together has evolved over the past decade, the basics remain the same: to combine multiple metrics of popularity into a set of rankings that reflect the varying needs of different readers.\\n\"}, {\"url\": \"https://www.hackerrank.com/blog/most-popular-languages-2023/\", \"content\": \"PHP\\nWhat this language is used for:\\nPHP is a widely-used open source and general-purpose scripting language that is especially suited for web development.\\n What this language is used for:\\nPython is an interpreted, high-level, general-purpose programming language, and one of the most popular languages for rapid development.\\n TypeScript\\nWhat this language is used for:\\nTypeScript is an open-source, object-oriented language that is an extension of JavaScript, meaning JavaScript code is valid TypeScript code. From the supremacy of Java and Python to the rise of Go and TypeScript, 2023 is on track to be a pivotal year for developer skills.\\n JavaScript\\nWhat this language is used for:\\nJavaScript is a dynamic scripting language used for adding interactive behavior to web pages and applications.\"}]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGoodbye!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m graph\u001B[38;5;241m.\u001B[39mstream({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: [(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, user_input)]}):\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m value \u001B[38;5;129;01min\u001B[39;00m event\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m     10\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], BaseMessage):\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\littleagent-Hn7clQwO-py3.10\\lib\\site-packages\\langgraph\\pregel\\__init__.py:949\u001B[0m, in \u001B[0;36mPregel.stream\u001B[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001B[0m\n\u001B[0;32m    943\u001B[0m end_time \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    944\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_timeout \u001B[38;5;241m+\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m    945\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_timeout\n\u001B[0;32m    946\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    947\u001B[0m )\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m futures:\n\u001B[1;32m--> 949\u001B[0m     done, inflight \u001B[38;5;241m=\u001B[39m \u001B[43mconcurrent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfutures\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    950\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    951\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_when\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcurrent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfutures\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFIRST_COMPLETED\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    952\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_time\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmonotonic\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    953\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mend_time\u001B[49m\n\u001B[0;32m    954\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    955\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    956\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m fut \u001B[38;5;129;01min\u001B[39;00m done:\n\u001B[0;32m    957\u001B[0m         task \u001B[38;5;241m=\u001B[39m futures\u001B[38;5;241m.\u001B[39mpop(fut)\n",
      "File \u001B[1;32mD:\\Python310\\lib\\concurrent\\futures\\_base.py:307\u001B[0m, in \u001B[0;36mwait\u001B[1;34m(fs, timeout, return_when)\u001B[0m\n\u001B[0;32m    303\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001B[0;32m    305\u001B[0m     waiter \u001B[38;5;241m=\u001B[39m _create_and_install_waiters(fs, return_when)\n\u001B[1;32m--> 307\u001B[0m \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m fs:\n\u001B[0;32m    309\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m f\u001B[38;5;241m.\u001B[39m_condition:\n",
      "File \u001B[1;32mD:\\Python310\\lib\\threading.py:607\u001B[0m, in \u001B[0;36mEvent.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    605\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[0;32m    606\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[1;32m--> 607\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[1;32mD:\\Python310\\lib\\threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T15:35:00.657085400Z",
     "start_time": "2024-06-21T15:34:12.201425300Z"
    }
   },
   "id": "ac6bc2640b9f1e87"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "llm_config = {\n",
    "    \"provider\":\"openai\",\n",
    "    \"model\":\"gpt-4o-ca\"\n",
    "}\n",
    "llm = get_llms(llm_config)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # This is new!\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note: can also interrupt __after__ actions, if desired.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T15:47:30.157625300Z",
     "start_time": "2024-06-21T15:47:30.122229600Z"
    }
   },
   "id": "c89b68a08c62c8ff"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_SMqqfSNyCyB2abyQdwpUua5n)\n",
      " Call ID: call_SMqqfSNyCyB2abyQdwpUua5n\n",
      "  Args:\n",
      "    query: LangGraph overview\n",
      "  tavily_search_results_json (call_lwR0Gz4RVuJSPgAKTIBBVedq)\n",
      " Call ID: call_lwR0Gz4RVuJSPgAKTIBBVedq\n",
      "  Args:\n",
      "    query: LangGraph programming language features\n",
      "  tavily_search_results_json (call_ezBwrsw01Xdav18I6Qi54QpN)\n",
      " Call ID: call_ezBwrsw01Xdav18I6Qi54QpN\n",
      "  Args:\n",
      "    query: LangGraph use cases\n",
      "  tavily_search_results_json (call_FzISQqhJdcmnapUdGI8yndRF)\n",
      " Call ID: call_FzISQqhJdcmnapUdGI8yndRF\n",
      "  Args:\n",
      "    query: LangGraph tutorials\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T15:48:41.506769700Z",
     "start_time": "2024-06-21T15:48:34.792683700Z"
    }
   },
   "id": "231f17d7c28d8ffb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "896380e64e42ae6d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
